name: Ollama Local Config
version: 1.0.0

# --- Models Configuration ---
models:
  - name: "Coder Agent (Qwen Coder)"
    provider: ollama
    apiBase: http://design:11434
    model: qwen3-coder:latest
    roles: [chat, autocomplete, edit, apply]
  
  - name: "Nomic Embed"
    provider: ollama
    apiBase: http://design:11434
    model: nomic-embed-text:latest
    roles: [embed]

  - name: "Qwen3 Reranker"
    provider: ollama
    apiBase: http://design:11434
    model: dengcao/Qwen3-Reranker-8B:Q8_0
    roles: [rerank]

    # --- Context Providers ---
context:
  - provider: codebase
  - provider: file
  - provider: terminal

# --- Rules ---
rules:
  - "Use British English (optimise, centre) and quote prices in GBP (Â£)."
  - "When providing diagrams, format responses for Obsidian using Mermaid or SVG."
  - "Distance in miles, fuel in gallons, temperature in Celsius."
  - "Always assume the project root is D:/python/email-sorter/ unless otherwise specified. Never use placeholder paths like /path/to/."
  - "This project uses Miniforge/Conda and npm, not Docker. Do not suggest Docker-based solutions."
  - "Always prioritize context retrieved from @qdrant-mcp over general programming knowledge for project-specific architecture."
  - "Remember the project is split: Small_One is the local workstation (Windows/UK) and Design PC is the remote Qdrant/Ollama server."
